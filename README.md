Hello!

This is VocalEyes

Vocal Eyes is a minimalist accessibility web app designed to help blind and visually impaired users understand their surroundings.
It allows users to trigger the app with a voice command (â€œScanâ€), capture a photo automatically, generate a description of the scene using AI, and then listen to the description via text-to-speech â€” all in a seamless flow.

Features

ğŸ§  AI-Powered Description â€“ Generates a short description of the scene.<br>
ğŸ”Š Text-to-Speech â€“ Reads the description out loud.<br>
ğŸ”’ Minimal UI â€“ Designed for accessibility and ease of use.<br>
ğŸŒ Multi-Language Support â€“ Works in 10+ languages, configurable by the user.<br>
ğŸ¤– Google Assistant Integration â€“ Open the app by saying â€œScanâ€.<br>


ğŸš€ Getting Started

1. Clone the repository

```Bash
git clone https://github.com/Daiwik2005/vocal-eyes.git
cd vocal-eyes
```

2. Install dependencies

```Bash
pip install -r requirements.txt
```

3. Add your API keys (Important)

Streamlit requires secrets to be stored in a .streamlit/secrets.toml file.
Create a folder named .streamlit in your project root and add a secrets.toml file like this:

<h4># .streamlit/secrets.toml</h4>
```Bash
[api_keys]
gemini_api = "your_gemini_api_key_here"
# Add other keys here if needed
```


ğŸ”‘ Without this file, the app will not work.

4. Run the app

```Bash
streamlit run app.py
```



ğŸ› ï¸ Tech Stack

Frontend: Streamlit (minimalist web UI)<br>
AI Model: Google Gemini API (for image description)<br>
TTS: Streamlit / Python text-to-speech libraries<br>
Voice Assistant: Google Assistant Action to launch app<br>

Enjoy!!